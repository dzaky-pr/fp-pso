name: "ðŸ›  CI Pipeline"

on:
  workflow_dispatch:
  push:
    branches:
      - main

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build:
    name: ðŸš€ Build & Upload Artifacts
    runs-on: ubuntu-latest

    env:
      AWS_REGION: ap-southeast-1

    steps:
      - name: â¬‡ Checkout Code (repository)
        uses: actions/checkout@v4

      - name: âŽ” Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: ðŸ’¾ Cache Next.js Build
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            ${{ github.workspace }}/.next/cache
          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}
          restore-keys: |
            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-

      - name: â›… Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6

      - name: ðŸŒ± Terraform Init
        run: terraform -chdir=./terraform init
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: ðŸ“¦ Terraform Output
        id: tf_output
        run: |
          terraform -chdir=./terraform output -json > tf_output.json

          # Mask sensitive values in logs
          CI_ACCESS_KEY=$(jq -r '.ci_access_key_id.value' tf_output.json)
          CI_SECRET_KEY=$(jq -r '.ci_secret_access_key.value' tf_output.json)
          echo "::add-mask::$CI_ACCESS_KEY"
          echo "::add-mask::$CI_SECRET_KEY"

          echo "api_gateway_url=$(jq -r '.api_gateway_url.value' tf_output.json)" >> $GITHUB_OUTPUT
          echo "artifact_bucket=$(jq -r '.artifact_bucket_name.value' tf_output.json)" >> $GITHUB_OUTPUT
          echo "ci_access_key_id=$CI_ACCESS_KEY" >> $GITHUB_OUTPUT
          echo "ci_secret_access_key=$CI_SECRET_KEY" >> $GITHUB_OUTPUT
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: âœ… Check Terraform Output
        run: |
          echo "API Gateway URL: ${{ steps.tf_output.outputs.api_gateway_url }}"
          echo "Artifact Bucket: ${{ steps.tf_output.outputs.artifact_bucket }}"

      - name: ðŸ“¦ Install Dependencies With Audit
        run: |
          # Install with audit and cache optimization
          npm ci --prefer-offline  --cache ~/.npm

      - name: ðŸ” Lint & Typecheck
        run: |
          npm run lint
          npm run typecheck

      - name: ðŸ§ª Run Unit Tests
        run: |
          npm test -- --verbose

      - name: ðŸ— Setup .env
        run: |
          echo "AWS_API_URL=${{ steps.tf_output.outputs.api_gateway_url }}" >> .env

      - name: ðŸ— Build Next.js App
        run: npm run build

      - name: ðŸ“¦ Prepare Package Artifacts
        run: |
          mkdir -p artifact
          cp -r .next/static .next/standalone/.next
          cp -r .next/standalone artifact/

      - name: ðŸ“¦ Zip Artifacts
        run: |
          cd artifact && zip -r ../artifact.zip . -x "*.log" "*.tmp" "node_modules/*"

      - name: ðŸ” Verify Artifact Integrity
        run: |
          # Generate checksum for artifact
          sha256sum artifact.zip > artifact.zip.sha256
          echo "Artifact size: $(ls -lh artifact.zip | awk '{print $5}')"

          # Verify minimum size (should be > 1MB for a real deployment)
          ARTIFACT_SIZE=$(stat -f%z artifact.zip 2>/dev/null || stat -c%s artifact.zip)
          if [ "$ARTIFACT_SIZE" -lt 1048576 ]; then
            echo "::warning::Artifact size seems small ($ARTIFACT_SIZE bytes)"
          fi

      - name: â˜ Upload Artifact Zip to S3
        run: |
          aws s3 cp artifact.zip s3://${{ steps.tf_output.outputs.artifact_bucket }}/${{ github.sha }}.zip
        env:
          AWS_ACCESS_KEY_ID: ${{ steps.tf_output.outputs.ci_access_key_id }}
          AWS_SECRET_ACCESS_KEY: ${{ steps.tf_output.outputs.ci_secret_access_key }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: ðŸ“„ Backup latest.txt to previous.txt (if it exists)
        run: |
          set +e
          aws s3 cp s3://${{ steps.tf_output.outputs.artifact_bucket }}/latest.txt ./latest.txt
          if [ -f latest.txt ]; then
            echo "âœ… Found latest.txt, backing up to previous.txt"
            aws s3 cp ./latest.txt s3://${{ steps.tf_output.outputs.artifact_bucket }}/previous.txt
          else
            echo "â„¹ï¸ No latest.txt found, skipping backup."
          fi
        env:
          AWS_ACCESS_KEY_ID: ${{ steps.tf_output.outputs.ci_access_key_id }}
          AWS_SECRET_ACCESS_KEY: ${{ steps.tf_output.outputs.ci_secret_access_key }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: ðŸ“„ Write and Upload latest.txt
        run: |
          echo "${{ github.sha }}.zip" > latest.txt
          aws s3 cp latest.txt s3://${{ steps.tf_output.outputs.artifact_bucket }}/latest.txt
          echo "âœ… latest.txt now points to ${{ github.sha }}.zip"
        env:
          AWS_ACCESS_KEY_ID: ${{ steps.tf_output.outputs.ci_access_key_id }}
          AWS_SECRET_ACCESS_KEY: ${{ steps.tf_output.outputs.ci_secret_access_key }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: ðŸ§¹ Clean Up Old Artifacts in S3
        run: |
          aws s3 cp s3://${{ steps.tf_output.outputs.artifact_bucket }}/latest.txt latest.txt || true
          aws s3 cp s3://${{ steps.tf_output.outputs.artifact_bucket }}/previous.txt previous.txt || true

          LATEST=$(cat latest.txt 2>/dev/null | xargs || echo "")
          PREVIOUS=$(cat previous.txt 2>/dev/null | xargs || echo "")

          echo "Keeping: [$LATEST] and [$PREVIOUS]"

          aws s3 ls s3://${{ steps.tf_output.outputs.artifact_bucket }}/ | awk '{print $4}' | grep '\.zip$' > all_zips.txt || true

          if [ -f all_zips.txt ]; then
            while read ZIPFILE; do
              if [[ -n "$ZIPFILE" && "$ZIPFILE" != "$LATEST" && "$ZIPFILE" != "$PREVIOUS" ]]; then
                echo "ðŸ—‘ Deleting $ZIPFILE"
                aws s3 rm s3://${{ steps.tf_output.outputs.artifact_bucket }}/$ZIPFILE
              else
                echo "âœ… Keeping $ZIPFILE"
              fi
            done < all_zips.txt
          fi
        env:
          AWS_ACCESS_KEY_ID: ${{ steps.tf_output.outputs.ci_access_key_id }}
          AWS_SECRET_ACCESS_KEY: ${{ steps.tf_output.outputs.ci_secret_access_key }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: ðŸ§¹ Clean artifacts and zip
        run: |
          rm -rf artifact artifact.zip
          mkdir artifact
